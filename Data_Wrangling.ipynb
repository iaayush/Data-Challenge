{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = open(\"training_docs.txt\",encoding='utf-8')\n",
    "traindata = trainfile.readlines()\n",
    "trainfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = open(\"testing_docs.txt\",encoding='utf-8')\n",
    "testdata = testfile.readlines()\n",
    "testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelfile = open(\"training_labels_final.txt\",encoding='utf-8')\n",
    "trainlabel = labelfile.readlines()\n",
    "labelfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = []\n",
    "for i in range(0,len(testdata),4):\n",
    "    test_id.append(testdata[i])\n",
    "    \n",
    "test_text = []\n",
    "for i in range(1,len(testdata),4):\n",
    "    test_text.append(testdata[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = []\n",
    "for i in range(0,len(traindata),4):\n",
    "    train_id.append(traindata[i])\n",
    "    \n",
    "train_text = []\n",
    "for i in range(1,len(traindata),4):\n",
    "    train_text.append(traindata[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID tr_doc_1\\n</td>\n",
       "      <td>TEXT Two German tourists have been found safe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID tr_doc_2\\n</td>\n",
       "      <td>TEXT ACT police have seized a rare drug during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID tr_doc_3\\n</td>\n",
       "      <td>TEXT A 50-year-old Brisbane man has been charg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID tr_doc_4\\n</td>\n",
       "      <td>TEXT In-depth discussions are continuing to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID tr_doc_5\\n</td>\n",
       "      <td>TEXT Homicide detectives are still questioning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               text\n",
       "0  ID tr_doc_1\\n  TEXT Two German tourists have been found safe ...\n",
       "1  ID tr_doc_2\\n  TEXT ACT police have seized a rare drug during...\n",
       "2  ID tr_doc_3\\n  TEXT A 50-year-old Brisbane man has been charg...\n",
       "3  ID tr_doc_4\\n  TEXT In-depth discussions are continuing to re...\n",
       "4  ID tr_doc_5\\n  TEXT Homicide detectives are still questioning..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(\n",
    "    {   'ID': train_id,\n",
    "        'text': train_text\n",
    "    })\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID te_doc_1\\n</td>\n",
       "      <td>TEXT The Police Royal Commission in Western Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID te_doc_2\\n</td>\n",
       "      <td>TEXT The Northern Territory Government says it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID te_doc_3\\n</td>\n",
       "      <td>TEXT A group of hepatitis C sufferers, who wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID te_doc_4\\n</td>\n",
       "      <td>TEXT The crew of the North Korean vessel Pong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID te_doc_5\\n</td>\n",
       "      <td>TEXT The New South Wales Supreme Court has bee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               text\n",
       "0  ID te_doc_1\\n  TEXT The Police Royal Commission in Western Au...\n",
       "1  ID te_doc_2\\n  TEXT The Northern Territory Government says it...\n",
       "2  ID te_doc_3\\n  TEXT A group of hepatitis C sufferers, who wer...\n",
       "3  ID te_doc_4\\n  TEXT The crew of the North Korean vessel Pong ...\n",
       "4  ID te_doc_5\\n  TEXT The New South Wales Supreme Court has bee..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df = pd.DataFrame(\n",
    "    {   'ID': test_id,\n",
    "        'text': test_text\n",
    "    })\n",
    "\n",
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ID'] = train_df['ID'].map(lambda x: x.lstrip('ID').rstrip('\\n'))\n",
    "train_df['text'] = train_df['text'].map(lambda x: x.lstrip('TEXT').rstrip('\\n'))\n",
    "\n",
    "testing_df['ID'] = testing_df['ID'].map(lambda x: x.lstrip('ID').rstrip('\\n'))\n",
    "testing_df['text'] = testing_df['text'].map(lambda x: x.lstrip('TEXT').rstrip('\\n'))\n",
    "\n",
    "train_doc_id = train_df['ID']\n",
    "test_doc_id = testing_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = [re.sub(\"tr_doc_\\d*\",\"\",elem) for elem in trainlabel]\n",
    "trainlabel = [t.rstrip().lstrip() for t in trainlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [train_df, testing_df]\n",
    "combined = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "combined['text']=combined['text'].str.lower()\n",
    "\n",
    "tokenise = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['text']=combined['text'].apply(lambda x: tokenise.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "combined['text'] = combined.text.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNonAplhabet(text):\n",
    "    return [w for w in text if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.text = combined.text.apply(removeNonAplhabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133055, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['text']=combined['text'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"text_ngram3\"] = \"\"\n",
    "combined[\"text_ngram3\"] = combined[\"text\"].apply(lambda x: list(ngrams(x,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = {}\n",
    "for i in combined[\"text_ngram3\"]:\n",
    "    for j in i:\n",
    "        if j in trigram:\n",
    "            trigram[j] += 1\n",
    "        else:\n",
    "            trigram[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trigrams = []\n",
    "for k,v in trigram.items():\n",
    "    if v > 1064:\n",
    "        selected_trigrams.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_trigrams = MWETokenizer(selected_trigrams)\n",
    "\n",
    "combined[\"text\"] = combined[\"text\"].apply(tokens_trigrams.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"text_ngram2\"] = \"\"\n",
    "combined[\"text_ngram2\"] = combined[\"text\"].apply(lambda x: list(ngrams(x,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = {}\n",
    "for i in combined[\"text_ngram2\"]:\n",
    "    for j in i:\n",
    "        if j in bigram:\n",
    "            bigram[j] += 1\n",
    "        else:\n",
    "            bigram[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_bigram = []\n",
    "for k,v in bigram.items():\n",
    "    if v > 2112 and v < 104313:\n",
    "        selected_bigram.append(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_bigram = MWETokenizer(selected_bigram)\n",
    "\n",
    "combined[\"text\"] = combined[\"text\"].apply(tokens_bigram.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"text_ngram1\"] = \"\"\n",
    "combined[\"text_ngram1\"] = combined[\"text\"].apply(lambda x: list(ngrams(x,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = {}\n",
    "for i in combined[\"text_ngram1\"]:\n",
    "    for j in i:\n",
    "        if j in unigram:\n",
    "            unigram[j] += 1\n",
    "        else:\n",
    "            unigram[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_unigrams = []\n",
    "for k,v in unigram.items():\n",
    "    if v > 2539 and v < 103600:\n",
    "        selected_unigrams.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_unigrams = MWETokenizer(selected_unigrams)\n",
    "\n",
    "combined[\"text\"] = combined[\"text\"].apply(tokens_unigrams.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1377"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list = []\n",
    "for i in range(len(selected_unigrams)):\n",
    "    final_list.append(selected_unigrams[i][0])\n",
    "    \n",
    "for i in range(len(selected_bigram)):\n",
    "    final_list.append(selected_bigram[i][0])\n",
    "\n",
    "for i in range(len(selected_trigrams)):\n",
    "    final_list.append(selected_trigrams[i][0])\n",
    "    \n",
    "len(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['text_final'] = ''\n",
    "combined['text_final'] = combined['text'].apply(lambda x: [item for item in x if item in final_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['final'] = combined['text_final'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame(vectorizer.fit_transform(combined['final']).toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = combined_df[0:106445]\n",
    "test_df = combined_df[106445:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_id = list(train_doc_id)\n",
    "test_doc_id = list(test_doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['doc_id'] = \"\"\n",
    "train_df['label'] = \"\"\n",
    "\n",
    "train_df['doc_id'] = train_doc_id\n",
    "train_df['label'] = trainlabel\n",
    "\n",
    "\n",
    "test_df['doc_id'] = \"\"\n",
    "test_df['doc_id'] = test_doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_dataset.csv\",encoding='utf8',sep=\",\")\n",
    "test_df.to_csv(\"test_dataset.csv\",encoding='utf8',sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
